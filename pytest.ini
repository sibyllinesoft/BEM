[tool:pytest]
# Test discovery
minversion = 7.4
testpaths = tests
python_files = test_*.py *_test.py tests.py
python_classes = Test*
python_functions = test_*

# Output configuration
addopts = 
    -ra
    --strict-markers
    --strict-config
    --tb=short
    --maxfail=5
    --disable-warnings
    # Coverage options (can be overridden by tox/CI)
    --cov=src
    --cov-report=term-missing:skip-covered
    --cov-fail-under=80
    # Performance options
    --timeout=300
    --durations=10
    # Parallel execution (install pytest-xdist)
    -n auto
    # Rich output formatting
    --tb=line

# Warning filters
filterwarnings =
    error
    # Ignore common third-party warnings
    ignore::UserWarning
    ignore::DeprecationWarning:transformers.*
    ignore::DeprecationWarning:torch.*
    ignore::DeprecationWarning:numpy.*
    ignore::PendingDeprecationWarning
    # Ignore specific known warnings
    ignore:.*Using or importing the ABCs.*:DeprecationWarning
    ignore:.*distutils\.util\.strtobool.*:DeprecationWarning
    ignore:.*pkg_resources.*:DeprecationWarning
    # ML/AI specific warnings
    ignore:.*not compiled with CUDA support.*:UserWarning
    ignore:.*Some weights of.*were not initialized.*:UserWarning
    ignore:.*Using the `WANDB_DISABLED.*:UserWarning

# Test markers
markers =
    # Performance markers
    slow: marks tests as slow (deselect with '-m "not slow"')
    gpu: marks tests that require GPU/CUDA support
    integration: marks tests as integration tests (require external services)
    
    # Functional markers  
    unit: marks tests as unit tests (fast, isolated)
    api: marks tests that test API endpoints
    cli: marks tests that test command-line interfaces
    
    # Domain-specific markers
    research: marks tests for research functionality
    multimodal: marks tests for multimodal capabilities
    safety: marks safety and security related tests
    performance: marks performance benchmarking tests
    
    # Infrastructure markers
    redis: marks tests that require Redis
    postgres: marks tests that require PostgreSQL
    docker: marks tests that require Docker
    network: marks tests that require network access
    
    # ML-specific markers
    model_training: marks tests that involve model training
    model_inference: marks tests that involve model inference
    large_model: marks tests that use large models (>1GB)
    distributed: marks tests for distributed training
    
    # Stability markers
    flaky: marks tests that are known to be flaky
    experimental: marks tests for experimental features
    deprecated: marks tests for deprecated functionality

# Test timeout configuration
timeout = 300
timeout_method = thread

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test data and fixtures
cache_dir = .pytest_cache
tmp_path_retention_count = 3
tmp_path_retention_policy = "failed"

# Ignore paths during collection
norecursedirs = 
    .git
    .tox
    .eggs
    *.egg
    build
    dist
    archive
    models
    logs
    results/outputs
    deployment/dist

# Collection ignore patterns
collect_ignore = [
    "archive/",
    "models/",
    "logs/",
    "results/outputs/",
    "deployment/dist/",
    "scripts/demos/",
    "setup.py"
]

# xfail strict mode - xfail tests that pass will fail the test suite
xfail_strict = true

# Minimum Python version for tests
required_plugins = 
    pytest-cov>=4.1.0
    pytest-xdist>=3.3.0
    pytest-timeout>=2.2.0
    pytest-mock>=3.12.0
    pytest-asyncio>=0.21.0