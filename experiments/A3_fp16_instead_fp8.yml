base_config: performance_variant.yaml
metadata:
  experiment_id: A3_fp16_instead_fp8
  description: 'v1.3-stack ablation: FP16 instead of FP8 to test F5.4 efficiency contribution'
  version: 1.3.0-ablation-A3
  created: '2024-08-23'
  campaign: v1.3-stack-validation-phase3-ablations
  ablation_type: F5.4_fp8_qat_removal
  parent_config: S1_stack
  hypothesis: Removing FP8 QAT will maintain quality but increase latency/memory usage
model:
  base_model: microsoft/DialoGPT-small
  architecture: bem_v13_stack
  bem_config:
    sites:
    - W_O
    - W_down
    rank_schedule:
    - 2
    - 4
    - 8
    - 8
    - 8
    - 4
    - 2
    num_experts: 2
    alpha: 16.0
    dropout: 0.1
    svd_init:
      enabled: true
      init_file: artifacts/svd_init.pt
      freeze_steps: 50
    low_rank_diagonal:
      enabled: true
      diagonal_head: true
      clamp_norm_inf: 1.0
      include_in_budgets: true
    routing:
      chunk_size: 128
      hysteresis_tau: 0.7
      routing_type: chunk_sticky
    attention_bias:
      enabled: true
      retrieval_dim: 768
      bias_hidden_dim: 64
    governance:
      max_singular_value: 1.0
      fro_budget: 1.0
      trust_region: true
      track_spectra: true
hard_negatives:
  enabled: true
  corpus_file: data/hard_negs.jsonl
  contradiction_features: true
  consistency_features: true
  contradiction_penalty: 0.1
  delta_w_reduction: true
fp8_qat:
  enabled: false
  quantize_components: []
  quantization: none
  fake_quant: false
  tolerance_check: false
  tolerance_threshold: null
  auto_fallback: false
  precision: fp16
  mixed_precision: true
training:
  seeds:
  - 1
  - 2
  - 3
  - 4
  - 5
  learning_rate: 8e-5
  batch_size: 8
  max_steps: 300
  warmup_steps: 30
  optimizer: adamw
  weight_decay: 0.01
  grad_clip_norm: 1.0
  save_steps: 50
  eval_steps: 50
  fp16: true
  bf16: false
data:
  train_file: data/train.jsonl
  eval_file: data/val.jsonl
  max_seq_length: 512
  retrieval:
    index_file: indices/retrieval.faiss
    num_retrieved: 15
    retrieval_model: sentence-transformers/all-mpnet-base-v2
    include_hard_negatives: true
    hard_neg_ratio: 0.3
evaluation:
  metrics:
  - EM
  - F1
  - BLEU
  - chrF
  slices:
    slice_a:
      name: Retrieval-Strong
      type: retrieval_strong
      coverage_threshold: 0.8
    slice_b:
      name: Full
      type: full
  performance_metrics:
  - p50_latency_ms
  - p95_latency_ms
  - throughput_tokens_per_sec
  - vram_usage_gb
  - cache_hit_rate_pct
  - memory_bandwidth_gb_per_sec
  - inference_time_per_token_ms
  telemetry:
    flips_per_token: true
    gate_entropy: true
    gate_utilization: true
    delta_w_norms: true
    top_singular_values: true
    numerical_precision: true
    quantization_error: false
  index_swap_test:
    enabled: true
    indices:
    - indices/clean.faiss
    - indices/shuffled.faiss
    - indices/corrupt.faiss
  cache_monitoring:
    enabled: true
    track_kv_hits: true
    track_routing_flips: true
    track_gate_entropy: true
    export_routing_decisions: true
quality_gates:
  stack_validation:
    enabled: true
    slice_b_improvement: true
    min_significant_metrics: 1
  latency_budget:
    enabled: true
    max_increase_pct: 25.0
  cache_performance:
    enabled: true
    min_hit_rate_pct: 80.0
  vram_budget:
    enabled: true
    max_delta_pct: 10.0
  param_parity:
    enabled: true
    tolerance_pct: 5.0
    baseline_params: 10070016
    baseline_flops: 13740539904
safety:
  verify_cache_safety: true
  forbidden_sites:
  - W_Q
  - W_K
  - W_V
  validate_svd_init: true
  validate_diagonal_head: true
  validate_hard_negatives: true
  validate_fp8_numerics: false
  validate_fp16_numerics: true
  validate_param_budget: true
  max_param_increase_pct: 5.0
  abort_on_breach: true
logging:
  log_level: INFO
  wandb_project: bem_v13_stack_validation_phase3
  wandb_tags:
  - A3
  - ablation
  - fp16_instead_fp8
  - F54_ablation
  - efficiency_test
  log_metrics:
  - loss
  - eval_metrics
  - system_telemetry
  - cache_metrics
  - routing_metrics
  - governance_metrics
  - hard_neg_metrics
  - svd_metrics
  - fp16_metrics
  export_formats:
  - jsonl
  - csv
  export_detailed_telemetry: true
analysis:
  stats_config:
    n_bootstrap: 10000
    alpha: 0.05
    fdr_method: fdr_bh
    paired_analysis: true
  aggregate_config:
    metrics:
    - EM
    - F1
    - BLEU
    - chrF
    slice: slice_b
    relative_improvement: true
  ablation_analysis:
    enabled: true
    baseline_config: S1_stack
    expected_direction: neutral_quality_higher_cost
    causality_test: true
    min_effect_size: 0.01
    efficiency_metrics:
    - latency_per_quality_unit
    - memory_per_quality_unit
    - energy_per_inference
reproducibility:
  ablation_type: F5.4_fp8_qat_removal
  code_version: bem_v1.3.0-ablation
  parent_hash: null
  svd_init_hash: null
  hard_neg_hash: null
  fp8_config_hash: null
  fp16_config_hash: null
