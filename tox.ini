[tox]
envlist = 
    py39,
    py310,
    py311,
    py312,
    pypy3,
    lint,
    type,
    security,
    docs,
    coverage-report
isolated_build = true
skip_missing_interpreters = true

[gh-actions]
python =
    3.9: py39
    3.10: py310
    3.11: py311, lint, type, security, docs
    3.12: py312
    pypy-3.9: pypy3

[testenv]
description = Run tests with pytest
deps =
    -r requirements.txt
    -r requirements-dev.txt
extras = 
    dev
    gpu: gpu
    performance: performance
commands =
    pytest {posargs:tests/} \
        --verbose \
        --tb=short \
        --cov=src \
        --cov-append \
        --cov-report=term-missing \
        --timeout=300
setenv =
    PYTHONPATH = {toxinidir}/src
    COVERAGE_FILE = {toxworkdir}/.coverage.{envname}
    # Disable CUDA for CPU-only testing environments
    CUDA_VISIBLE_DEVICES = ""
passenv = 
    CI
    GITHUB_*
    CODECOV_*
    PYTEST_*

[testenv:py39]
description = Run tests on Python 3.9 (minimum supported version)

[testenv:py310]
description = Run tests on Python 3.10

[testenv:py311]
description = Run tests on Python 3.11 (primary development version)

[testenv:py312]
description = Run tests on Python 3.12 (latest stable)

[testenv:pypy3]
description = Run tests on PyPy3
# Skip some heavy dependencies for PyPy
deps =
    pytest>=7.4.0
    pytest-cov>=4.1.0
    pytest-timeout>=2.2.0
    torch>=2.0.0
    numpy>=1.21.0
    scipy>=1.9.0
commands =
    pytest {posargs:tests/} \
        --verbose \
        --tb=short \
        -m "not gpu and not slow" \
        --timeout=60

[testenv:lint]
description = Run linting checks
deps =
    -r requirements.txt
    black>=23.0.0
    isort>=5.12.0
    flake8>=6.0.0
    flake8-docstrings
    flake8-bugbear
    flake8-comprehensions
    flake8-simplify
    pydocstyle>=6.3.0
commands =
    black --check --diff src/ tests/ scripts/
    isort --check-only --diff src/ tests/ scripts/
    flake8 src/ tests/ scripts/
    pydocstyle src/ --convention=google

[testenv:type]
description = Run type checking with mypy
deps =
    -r requirements.txt
    mypy>=1.7.0
    types-PyYAML
    types-requests
    types-redis
commands =
    mypy src/ --install-types --non-interactive

[testenv:security]
description = Run security checks
deps =
    -r requirements.txt
    bandit[toml]>=1.7.5
    safety>=2.3.0
commands =
    bandit -r src/ -f json -o {toxworkdir}/bandit-report.json
    bandit -r src/
    safety check --json --output {toxworkdir}/safety-report.json
    safety check

[testenv:docs]
description = Build documentation
deps =
    -r requirements.txt
    -e .[docs]
changedir = {toxinidir}
commands =
    python -c "
    import os
    if not os.path.exists('mkdocs.yml'):
        print('Creating basic mkdocs.yml...')
        with open('mkdocs.yml', 'w') as f:
            f.write('''
site_name: BEM Documentation
site_description: Block-wise Expert Modules Documentation
theme:
  name: material
plugins:
  - search
  - mkdocstrings:
      handlers:
        python:
          options:
            show_source: false
nav:
  - Home: index.md
  - API: reference/
''')
        print('Created basic mkdocs.yml')
    "
    mkdocs build --strict --verbose

[testenv:docs-serve]
description = Serve documentation locally
deps =
    {[testenv:docs]deps}
commands =
    {[testenv:docs]commands}
    mkdocs serve

[testenv:coverage-report]
description = Generate coverage reports
deps =
    coverage[toml]>=7.0.0
commands =
    coverage combine
    coverage report --show-missing --fail-under=80
    coverage html -d {toxworkdir}/htmlcov
    coverage xml -o {toxworkdir}/coverage.xml
depends = py39,py310,py311,py312

[testenv:integration]
description = Run integration tests with external services
deps =
    {[testenv]deps}
    docker-compose
setenv =
    {[testenv]setenv}
    REDIS_URL = redis://localhost:6379
    DATABASE_URL = postgresql://postgres:postgres@localhost:5432/bem_test
commands_pre =
    docker-compose -f docker-compose.test.yml up -d
    # Wait for services to be ready
    python -c "
    import time
    import redis
    import psycopg2
    
    # Wait for Redis
    for i in range(30):
        try:
            r = redis.Redis(host='localhost', port=6379)
            r.ping()
            print('Redis is ready')
            break
        except:
            time.sleep(1)
    
    # Wait for PostgreSQL
    for i in range(30):
        try:
            conn = psycopg2.connect('postgresql://postgres:postgres@localhost:5432/bem_test')
            conn.close()
            print('PostgreSQL is ready')
            break
        except:
            time.sleep(1)
    "
commands =
    pytest {posargs:tests/} -m integration --verbose --timeout=600
commands_post =
    docker-compose -f docker-compose.test.yml down

[testenv:gpu]
description = Run GPU-specific tests (requires CUDA)
deps =
    {[testenv]deps}
setenv =
    {[testenv]setenv}
    # Allow CUDA for GPU testing
    !CUDA_VISIBLE_DEVICES
commands =
    python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
    pytest {posargs:tests/} -m gpu --verbose --timeout=900

[testenv:benchmark]
description = Run performance benchmarks
deps =
    {[testenv]deps}
    pytest-benchmark>=4.0.0
commands =
    pytest tests/ -m "not slow" \
        --benchmark-only \
        --benchmark-json={toxworkdir}/benchmark.json \
        --benchmark-compare-fail=min:5% \
        --benchmark-compare-fail=max:10%

[testenv:research]
description = Research environment with all dependencies
deps =
    -r requirements.txt
    -e .[research,gpu,performance]
commands =
    python -c "
    print('Research environment ready!')
    print('Available tools:')
    import sys
    modules = ['jupyter', 'wandb', 'mlflow', 'optuna', 'ray', 'tensorboard']
    for module in modules:
        try:
            __import__(module)
            print(f'  ✓ {module}')
        except ImportError:
            print(f'  ✗ {module}')
    "

[testenv:clean]
description = Clean up build artifacts and cache
deps =
commands =
    python -c "
    import shutil
    import pathlib
    
    patterns = [
        '**/__pycache__',
        '**/*.pyc',
        '**/*.pyo', 
        '**/*.pyd',
        '**/build',
        '**/dist',
        '**/*.egg-info',
        '**/.coverage*',
        '**/htmlcov',
        '**/.pytest_cache',
        '**/.mypy_cache',
        '**/.tox',
    ]
    
    for pattern in patterns:
        for path in pathlib.Path('.').glob(pattern):
            if path.exists():
                if path.is_dir():
                    shutil.rmtree(path)
                    print(f'Removed directory: {path}')
                else:
                    path.unlink()
                    print(f'Removed file: {path}')
    "

[testenv:release]
description = Build release packages
deps =
    build>=0.10.0
    twine>=4.0.0
    wheel>=0.41.0
commands =
    python -m build --sdist --wheel
    twine check dist/*
    python -c "
    import pathlib
    import subprocess
    
    # List built packages
    print('Built packages:')
    for pkg in pathlib.Path('dist').glob('*'):
        print(f'  {pkg.name} ({pkg.stat().st_size} bytes)')
    
    # Test install
    wheels = list(pathlib.Path('dist').glob('*.whl'))
    if wheels:
        print(f'Testing installation of {wheels[0].name}...')
        result = subprocess.run(['pip', 'install', '--dry-run', str(wheels[0])], 
                               capture_output=True, text=True)
        if result.returncode == 0:
            print('✓ Package installation check passed')
        else:
            print('✗ Package installation check failed')
            print(result.stderr)
    "

[testenv:profile]
description = Run performance profiling
deps =
    {[testenv]deps}
    py-spy
    memory-profiler
    line-profiler
commands =
    python -c "
    print('Profiling tools available:')
    print('1. Run with py-spy: py-spy record -o profile.svg -- python script.py')  
    print('2. Run with memory profiler: mprof run script.py && mprof plot')
    print('3. Use @profile decorator and: kernprof -l -v script.py')
    "

[flake8]
max-line-length = 88
extend-ignore = E203, W503, E501
select = E9,F63,F7,F82
exclude = 
    .git,
    __pycache__,
    .tox,
    .eggs,
    *.egg,
    build,
    dist,
    archive

[coverage:run]
source = src
branch = true
omit = 
    */tests/*
    */test_*.py
    */conftest.py
    src/bem_legacy/*
    */migrations/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod